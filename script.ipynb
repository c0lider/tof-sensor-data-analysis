{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Erhebung und Analyse von Sensordaten - Time of flight Kamera\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Development environment\n",
    "\n",
    "The following lines will enable the autoreload extension for this Jupyter Notebook. This provides the functionality to automatically reload modules upon editing those, without the need to restart the entire kernel, thus making it necessary to re-run all cells before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "# '2' means that all modules will be reloaded automatically before executing any cell\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load data\n",
    "Get the input data sets inside 'Messdaten' as a dictionary with the following structure:\n",
    "```json\n",
    "{\n",
    "    'Input_path_1': np.array,\n",
    "    'Input_path_2': np.array,\n",
    "    // ...\n",
    "    \n",
    "}\n",
    "```\n",
    "Where `np.array` is a three dimensional array containing depth data frames of size 80 * 60 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import utilities\n",
    "\n",
    "\n",
    "input_file_paths = utilities.load_input_file_paths()\n",
    "data_sets = utilities.load_depth_data_sets(input_file_paths)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Visualize the data\n",
    "\n",
    "Save the loaded data frames as gif files to `output/<input-file-name>/raw.gif` and display them in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, Markdown, display\n",
    "\n",
    "display(Markdown('### Heatmap animations created for input data:'))\n",
    "\n",
    "for file_name, frames in data_sets.items():\n",
    "    try:\n",
    "        output_path = utilities.create_gif_from_frames(frames, f'output/{file_name}/raw.gif')\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "        continue\n",
    "\n",
    "    display(Image(filename=output_path, width=200), Markdown(f'*{file_name}*'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Manipulate the data\n",
    "\n",
    "1. Create a background map for each frame by calculating the mean depth map per sequence. \n",
    "2. Use the background map to subtract it from each frame in the sequence\n",
    "3. Create a foreground mask:  \n",
    "If the remaining depth value of a pixel is still bigger than a certain threshold, the pixel is considered foreground (value 1)\n",
    "Otherwise the pixel is part of the background (value 0)\n",
    "\n",
    "> The foreground masks are saved in a data structure similar to the original frame data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import filters\n",
    "import numpy as np\n",
    "\n",
    "display(Markdown('### Foreground masks created for input data:'))\n",
    "\n",
    "foreground_masks = {}\n",
    "\n",
    "for file_name, frames in data_sets.items():\n",
    "    background = filters.compute_background(frames)\n",
    "\n",
    "    foreground_mask = [filters.subtract_background_from_frame(frame, background, 1000) for frame in frames]\n",
    "    foreground_mask = np.stack(foreground_mask)\n",
    "    \n",
    "    foreground_masks[file_name] = foreground_mask\n",
    "    \n",
    "    try:\n",
    "        output_path = utilities.create_gif_from_frames(foreground_mask, f'output/{file_name}/foreground_mask.gif')\n",
    "\n",
    "        display(Image(filename=output_path, width=200))\n",
    "        display(Markdown(f'*{file_name}*'))\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "        continue\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Analyze the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "\n",
    "slider = widgets.IntSlider(\n",
    "    value=50,\n",
    "    min=1,\n",
    "    max=100,\n",
    "    step=1,\n",
    "    description='Person size:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d')\n",
    "display(Markdown('Specify the amount of pixels, a person should be represented by in the image:'))\n",
    "display(slider)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use cv2 to count shapes in each frame and count the shape as person if it has a certain size. The resulting array of detected people per frame is saved to a similar data structure as the input data (dictionary with file names as keys):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vision\n",
    "\n",
    "person_size = slider.value\n",
    "\n",
    "display(Markdown(f'*Counting people per sequence and calculating movement data...*'))\n",
    "\n",
    "people_counts = {}\n",
    "movement_data = {}\n",
    "\n",
    "for file_name, foreground_mask in foreground_masks.items():\n",
    "    # collect the amount of people per frame\n",
    "    people_counts[file_name] = [vision.count_people(mask, person_size=person_size) for mask in foreground_mask]\n",
    "\n",
    "    # collect movement data\n",
    "    movements_in_data_set = []\n",
    "    \n",
    "    for index in range(len(foreground_mask) - 1):\n",
    "        movements_in_data_set.append(vision.count_and_track_people_direction(foreground_mask[index], foreground_mask[index + 1]))\n",
    "\n",
    "    movement_data[file_name] = movements_in_data_set\n",
    "    \n",
    "    print(f'Max people in frame ({file_name}):', max(people_counts[file_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label each frame with the amount of people detected and mark center points for each detected person:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name in data_sets:\n",
    "    frame_texts = []\n",
    "    frame_points = []\n",
    "\n",
    "    for movement in movement_data[file_name]:\n",
    "        up = 0\n",
    "        down = 0\n",
    "        curr_points = []\n",
    "\n",
    "        for person in movement:\n",
    "            if person[2] == 'up':\n",
    "                up += 1\n",
    "            elif person[2] == 'down':\n",
    "                down += 1\n",
    "            person_x, person_y = person[0]\n",
    "            curr_points.append([person_x, person_y])\n",
    "\n",
    "        frame_points.append(curr_points)\n",
    "\n",
    "        frame_text = f'People: {len(movement)} Up: {up} Down: {down}'\n",
    "        frame_texts.append(frame_text)\n",
    "\n",
    "    utilities.add_text_to_gif(f'output/{file_name}/raw.gif', frame_texts)\n",
    "    utilities.add_points_to_gif(f'output/{file_name}/raw.gif', frame_points)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
